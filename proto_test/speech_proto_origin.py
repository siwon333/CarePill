# speech_realtime_fix_no_audio_block.py
# PyAudio + OpenAI Realtime (server_vad ìë™ í„´)
# - session.audio ë¸”ë¡ ì œê±° (ë°°í¬ì—ì„œ ë¯¸ì§€ì›)
# - voice/output_audio_format ë§Œìœ¼ë¡œ TTS
# - ì˜¤ë””ì˜¤/í…ìŠ¤íŠ¸ í™•ì‹¤íˆ ì¶œë ¥ + ì˜¤ë””ì˜¤ ìˆ˜ì‹  ê°ì‹œ

import asyncio
import websockets
import pyaudio
import base64
import json
import os
import time

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

API_KEY = os.getenv("OPENAI_API_KEY")

MODEL = "gpt-4o-mini-realtime-preview-2024-12-17"
VOICE = "verse"  # ì•ˆ ë‚˜ì˜¤ë©´ "alloy"ë¡œ ë°”ê¿” í…ŒìŠ¤íŠ¸

RATE = 24000
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1

audio = pyaudio.PyAudio()
input_stream = None
output_stream = None

def b64enc(data: bytes) -> str:
    return base64.b64encode(data).decode("utf-8")

def b64dec(b64: str) -> bytes:
    return base64.b64decode(b64)

def extract_text_from_completed(msg: dict) -> str:
    try:
        resp = msg.get("response") or {}
        output = resp.get("output") or []
        texts = []
        for item in output:
            if isinstance(item, dict):
                t1 = item.get("text")
                if isinstance(t1, str) and t1.strip():
                    texts.append(t1.strip())
                content = item.get("content")
                if isinstance(content, list):
                    for c in content:
                        if isinstance(c, dict):
                            t2 = c.get("text") or c.get("transcript")
                            if isinstance(t2, str) and t2.strip():
                                texts.append(t2.strip())
        if texts:
            return " ".join(texts)
    except Exception:
        pass
    return ""

async def run_realtime():
    global input_stream, output_stream, audio

    if not API_KEY:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    uri = f"wss://api.openai.com/v1/realtime?model={MODEL}"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "OpenAI-Beta": "realtime=v1"
    }

    # ì˜¤ë””ì˜¤ ì¥ì¹˜ ì—´ê¸°
    input_stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                              input=True, frames_per_buffer=CHUNK)
    output_stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE,
                               output=True, frames_per_buffer=CHUNK)

    print(f"ğŸ§ {MODEL} / voice={VOICE}")
    print("ğŸ™ï¸ ë§ˆì´í¬Â·ìŠ¤í”¼ì»¤ ì¤€ë¹„ ì™„ë£Œ. ì„œë²„ ì—°ê²° ì¤‘...")

    async with websockets.connect(uri, additional_headers=headers,
                                  ping_interval=20, ping_timeout=20) as ws:
        print("âœ… WebSocket ì—°ê²° ì™„ë£Œ")

        # === ì„¸ì…˜ ì—…ë°ì´íŠ¸ ===
        # âš ï¸ 'audio' ë¸”ë¡ ì‚­ì œ (ë°°í¬ì—ì„œ ë¯¸ì§€ì›)
        session_update = {
            "type": "session.update",
            "session": {
                "modalities": ["audio", "text"],
                "instructions": "You are CarePill, a friendly Korean assistant. Reply in Korean.",
                "voice": VOICE,                     # TTS ìŒì„±
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",     # TTS í¬ë§·
                "input_audio_transcription": {"model": "gpt-4o-transcribe"},
                "turn_detection": {"type": "server_vad", "create_response": True, "silence_duration_ms": 500}
            }
        }
        await ws.send(json.dumps(session_update))
        print("ğŸ§  ì„¸ì…˜ ì„¤ì • ì™„ë£Œ â€” ì„œë²„ê°€ ìë™ìœ¼ë¡œ í„´ì„ ê°ì§€í•©ë‹ˆë‹¤.\n")

        async def sender():
            # ì˜¤ë””ì˜¤ appendë§Œ (commit/response.create ê¸ˆì§€)
            while True:
                data = input_stream.read(CHUNK, exception_on_overflow=False)
                await ws.send(json.dumps({
                    "type": "input_audio_buffer.append",
                    "audio": b64enc(data)
                }))
                await asyncio.sleep(0.02)

        async def receiver():
            text_buf = ""
            user_buf = ""
            audio_chunks = 0
            last_audio_ts = time.time()

            while True:
                raw = await ws.recv()
                try:
                    msg = json.loads(raw)
                except Exception:
                    continue

                t = msg.get("type")

                # ì‚¬ìš©ì ì „ì‚¬
                if t and t.startswith("input_audio_transcription"):
                    tx = msg.get("transcript") or msg.get("text")
                    if tx and tx.strip():
                        user_buf += tx.strip() + " "
                        print(f"\rğŸ¤ YOU: {user_buf.strip()}", end="", flush=True)

                # ì‘ë‹µ ì‹œì‘
                elif t == "response.created":
                    text_buf = ""
                    print("\n\nğŸ¤– [ì‘ë‹µ ìƒì„± ì‹œì‘]")

                # í…ìŠ¤íŠ¸ ë¸íƒ€ (ëª¨ë“  ë³€í˜•)
                elif t in ("response.output_text.delta", "response.text.delta", "response.delta"):
                    delta = msg.get("delta", "")
                    if isinstance(delta, str) and delta:
                        text_buf += delta
                        print(delta, end="", flush=True)

                # ì˜¤ë””ì˜¤ ë¸íƒ€ (ëª¨ë“  ë³€í˜• + í•„ë“œ í˜¸í™˜)
                elif t in ("output_audio.delta", "response.output_audio.delta", "response.audio.delta"):
                    audio_b64 = msg.get("audio") or msg.get("delta")
                    if audio_b64:
                        output_stream.write(b64dec(audio_b64))
                        audio_chunks += 1
                        last_audio_ts = time.time()
                        if audio_chunks % 20 == 0:
                            print(f"\nğŸµ [ì˜¤ë””ì˜¤ ì¡°ê° ìˆ˜: {audio_chunks}]")

                # ì‘ë‹µ ì™„ë£Œ
                elif t in ("response.completed", "response.done", "response.text.done"):
                    final_text = text_buf.strip() or extract_text_from_completed(msg).strip()
                    if final_text:
                        print(f"\nâœ… CAREPILL: {final_text}\n")
                    else:
                        print("\nâœ… CAREPILL: (ìŒì„±ìœ¼ë¡œë§Œ ì‘ë‹µ)\n")
                    user_buf = ""  # ë‹¤ìŒ ë°œí™” ì¤€ë¹„
                    # 5ì´ˆê°„ ì˜¤ë””ì˜¤ê°€ í•œ ë²ˆë„ ì•ˆ ì™”ìœ¼ë©´ ê²½ê³ 
                    if time.time() - last_audio_ts > 5:
                        print("âš ï¸ ê²½ê³ : TTS ì˜¤ë””ì˜¤ê°€ ìˆ˜ì‹ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (voice ë³€ê²½ì„ ì‹œë„í•´ë³´ì„¸ìš”. ì˜ˆ: VOICE='alloy')")

                elif t == "error":
                    print(f"\nâ— ì„œë²„ ì˜¤ë¥˜: {msg}")

        await asyncio.gather(sender(), receiver())

if __name__ == "__main__":
    try:
        asyncio.run(run_realtime())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨")
    finally:
        try:
            if input_stream:
                if input_stream.is_active(): input_stream.stop_stream()
                input_stream.close()
            if output_stream:
                if output_stream.is_active(): output_stream.stop_stream()
                output_stream.close()
        except Exception:
            pass
        try:
            audio.terminate()
        except Exception:
            pass
        print("ğŸµ ì¢…ë£Œ")
